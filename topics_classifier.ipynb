{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b921ac",
   "metadata": {},
   "source": [
    "# Setup \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca8ace",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8755c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model files from 'trained_model' directory\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import topics_classifier_utils as tcu \n",
    "\n",
    "# Load pre-trained model (no API call - loads from local disk)\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Check if model files are in root directory or need to be extracted\n",
    "if os.path.exists('config.json') and os.path.exists('mlb.pkl'):\n",
    "    # Model files are already in root directory\n",
    "    model_path = '.'\n",
    "    print(\"Using model files from current directory\")\n",
    "elif os.path.exists('trained_model') and os.path.exists(os.path.join('trained_model', 'config.json')):\n",
    "    # Model is already extracted to trained_model directory\n",
    "    model_path = 'trained_model'\n",
    "    print(\"Using model files from 'trained_model' directory\")\n",
    "else:\n",
    "    # Need to extract from zip\n",
    "    print(\"Extracting model from zip file...\")\n",
    "    if not os.path.exists('trained_model'):\n",
    "        os.makedirs('trained_model', exist_ok=True)\n",
    "    with zipfile.ZipFile('trained_model.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('trained_model')\n",
    "    model_path = 'trained_model'\n",
    "    print(\"Model extracted successfully\")\n",
    "\n",
    "# Load from local path (no API call - local_files_only=True prevents HuggingFace API calls)\n",
    "model, tokenizer, mlb = tcu.load_trained_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8458cf9-cc63-4d4f-ae5a-4730da9f1f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'topics_classifier_utils' from '/scratch/midway3/aesteva/Speech-Multi-Classifier/topics_classifier_utils.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(tcu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af4de9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df_main = pd.read_excel(\"speeches_with_names.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3539cb",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74ddfbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28058, 4), (4284, 4), (23774, 4))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_keep = ['new_speech_id', 'topic', 'speech', 'ID']\n",
    "\n",
    "df_main = df_main[cols_to_keep]\n",
    "\n",
    "df_test = df_main[df_main['topic'].notna() & (df_main['topic'] != '')]\n",
    "\n",
    "df_candidates = df_main[df_main['topic'].isna() | (df_main['topic'] == '')]\n",
    "\n",
    "df_main.shape, df_test.shape, df_candidates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6d8885",
   "metadata": {},
   "source": [
    "# Training on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "934dc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BERT model on df_test\n",
    "\n",
    "# model, tokenizer, mlb, train_loader, val_loader = tcu.train_bert_multilabel(\n",
    "#     df=df_test,\n",
    "#     model_name='emanjavacas/MacBERTh',  # MacBERTh for historical/old English\n",
    "#     text_col='speech',\n",
    "#     label_col='topic',\n",
    "#     batch_size=4,  # Start small for CPU\n",
    "#     epochs=3,\n",
    "#     max_length=256  # Reduced to save memory\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc7320",
   "metadata": {},
   "source": [
    "## Step 3: Create Embedding Cache (Optimization)\n",
    "\n",
    "Create embeddings once and reuse them for faster predictions and threshold testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "116916c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Loading Embedding Cache from embedding_cache.pkl\n",
      "✓ Loaded 27785 embeddings from cache\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create embedding cache for df_candidates\n",
    "# This embeds all speeches once and saves them for reuse\n",
    "# Much faster when testing different thresholds and making predictions!\n",
    "\n",
    "embedding_cache = tcu.create_embedding_cache(\n",
    "    df_texts=df_main,\n",
    "    id_col='new_speech_id',  # ID column to use as cache key\n",
    "    text_col='speech',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256,\n",
    "    chunk_size=200,\n",
    "    batch_size=128,  # Adjust based on your GPU memory\n",
    "    cache_path='embedding_cache.pkl',  # Save cache to disk for reuse\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a73c3",
   "metadata": {},
   "source": [
    "# Predict on Unlabeled Data (Using Cached Embeddings)\n",
    "\n",
    "Now use the cached embeddings for fast predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88f5aec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting from 23774 cached embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting probabilities: 100%|██████████| 186/186 [00:00<00:00, 4054.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict topic probabilities for df_candidates using cached embeddings\n",
    "# This is MUCH faster than computing embeddings on-the-fly!\n",
    "\n",
    "df_candidates_with_predictions = tcu.predict_from_embedding_cache(\n",
    "    embedding_cache=embedding_cache,\n",
    "    df=df_candidates,\n",
    "    id_col='new_speech_id',\n",
    "    model=model,\n",
    "    mlb=mlb,\n",
    "    batch_size=128  # Can use larger batch size since embeddings are pre-computed\n",
    ")\n",
    "\n",
    "candidate_prob_cols = [col for col in df_candidates_with_predictions.columns if col.startswith('prob_')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ad78976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_speech_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>speech</th>\n",
       "      <th>ID</th>\n",
       "      <th>prob_Other</th>\n",
       "      <th>prob_Politics: Domestic</th>\n",
       "      <th>prob_Politics: Foreign</th>\n",
       "      <th>prob_Private Matters/Ceremonial</th>\n",
       "      <th>prob_Private Matters/Cerenomial</th>\n",
       "      <th>prob_Public Finance</th>\n",
       "      <th>prob_Religious Issues</th>\n",
       "      <th>prob_Trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trusty, and Well-beloved, We greet you well: I...</td>\n",
       "      <td>4599.0</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.868598</td>\n",
       "      <td>0.184695</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.203659</td>\n",
       "      <td>0.577442</td>\n",
       "      <td>0.012328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If the general Distraction and Confusion, whic...</td>\n",
       "      <td>4599.0</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.939967</td>\n",
       "      <td>0.085532</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.128325</td>\n",
       "      <td>0.226138</td>\n",
       "      <td>0.020901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dread Sovereign, Your faithful Subjects the Co...</td>\n",
       "      <td>4479.0</td>\n",
       "      <td>0.034297</td>\n",
       "      <td>0.945988</td>\n",
       "      <td>0.139780</td>\n",
       "      <td>0.080254</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.147302</td>\n",
       "      <td>0.146564</td>\n",
       "      <td>0.022458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sir, the House has taken very great Offence at...</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.966232</td>\n",
       "      <td>0.054771</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.214133</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>0.131877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'He, the King, had too ample a Manifestation ...</td>\n",
       "      <td>4599.0</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>0.971618</td>\n",
       "      <td>0.080788</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.256028</td>\n",
       "      <td>0.292590</td>\n",
       "      <td>0.016291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_speech_id topic                                             speech  \\\n",
       "0          70001   NaN  Trusty, and Well-beloved, We greet you well: I...   \n",
       "1          70002   NaN  If the general Distraction and Confusion, whic...   \n",
       "2          70003   NaN  Dread Sovereign, Your faithful Subjects the Co...   \n",
       "3          70004   NaN  Sir, the House has taken very great Offence at...   \n",
       "4          70005   NaN   'He, the King, had too ample a Manifestation ...   \n",
       "\n",
       "       ID  prob_Other  prob_Politics: Domestic  prob_Politics: Foreign  \\\n",
       "0  4599.0    0.023824                 0.868598                0.184695   \n",
       "1  4599.0    0.016579                 0.939967                0.085532   \n",
       "2  4479.0    0.034297                 0.945988                0.139780   \n",
       "3  2421.0    0.007718                 0.966232                0.054771   \n",
       "4  4599.0    0.016338                 0.971618                0.080788   \n",
       "\n",
       "   prob_Private Matters/Ceremonial  prob_Private Matters/Cerenomial  \\\n",
       "0                         0.037516                         0.004877   \n",
       "1                         0.034915                         0.002706   \n",
       "2                         0.080254                         0.004392   \n",
       "3                         0.023878                         0.002126   \n",
       "4                         0.022719                         0.002630   \n",
       "\n",
       "   prob_Public Finance  prob_Religious Issues  prob_Trials  \n",
       "0             0.203659               0.577442     0.012328  \n",
       "1             0.128325               0.226138     0.020901  \n",
       "2             0.147302               0.146564     0.022458  \n",
       "3             0.214133               0.027931     0.131877  \n",
       "4             0.256028               0.292590     0.016291  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_candidates_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ac5db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions (topics and probabilities) to 'candidates_with_predictions.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Save results to Excel\n",
    "df_candidates_with_predictions.to_excel('candidates_with_predictions.xlsx', index=False)\n",
    "print(\"Saved predictions (topics and probabilities) to 'candidates_with_predictions.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b67ac",
   "metadata": {},
   "source": [
    "## Step 2: Find Optimal Threshold\n",
    "\n",
    "Use validation set to find optimal threshold that minimizes FN (or FP) based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f35ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting from 4284 cached embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting probabilities: 100%|██████████| 34/34 [00:00<00:00, 3897.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_speech_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>speech</th>\n",
       "      <th>ID</th>\n",
       "      <th>prob_Other</th>\n",
       "      <th>prob_Politics: Domestic</th>\n",
       "      <th>prob_Politics: Foreign</th>\n",
       "      <th>prob_Private Matters/Ceremonial</th>\n",
       "      <th>prob_Private Matters/Cerenomial</th>\n",
       "      <th>prob_Public Finance</th>\n",
       "      <th>prob_Religious Issues</th>\n",
       "      <th>prob_Trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>My Lords and gentlemen; I hope that you do rem...</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.933067</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.050063</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>0.124481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>the king's main reason of calling the parliame...</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>0.015721</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.404397</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.580476</td>\n",
       "      <td>0.108299</td>\n",
       "      <td>0.011705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politics: Domestic, Religious Issues, Public F...</td>\n",
       "      <td>\"That his majesty had amply accepted the Speak...</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.960059</td>\n",
       "      <td>0.128712</td>\n",
       "      <td>0.037610</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.147314</td>\n",
       "      <td>0.132154</td>\n",
       "      <td>0.013860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>\"That the late dictates between the late King ...</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.984181</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>0.021698</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.103176</td>\n",
       "      <td>0.071109</td>\n",
       "      <td>0.043408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>there might be no Committees for Grievances or...</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.960703</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.530751</td>\n",
       "      <td>0.205464</td>\n",
       "      <td>0.012420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_speech_id                                              topic  \\\n",
       "0              1                                 Politics: Domestic   \n",
       "1              2                                 Politics: Domestic   \n",
       "2              3  Politics: Domestic, Religious Issues, Public F...   \n",
       "3              4                                 Politics: Domestic   \n",
       "4              5                                 Politics: Domestic   \n",
       "\n",
       "                                              speech       ID  prob_Other  \\\n",
       "0  My Lords and gentlemen; I hope that you do rem...  10001.0    0.011698   \n",
       "1  the king's main reason of calling the parliame...  10013.0    0.015721   \n",
       "2  \"That his majesty had amply accepted the Speak...  10013.0    0.023805   \n",
       "3  \"That the late dictates between the late King ...   1321.0    0.009132   \n",
       "4  there might be no Committees for Grievances or...    316.0    0.013387   \n",
       "\n",
       "   prob_Politics: Domestic  prob_Politics: Foreign  \\\n",
       "0                 0.933067                0.022387   \n",
       "1                 0.761333                0.404397   \n",
       "2                 0.960059                0.128712   \n",
       "3                 0.984181                0.024302   \n",
       "4                 0.960703                0.039627   \n",
       "\n",
       "   prob_Private Matters/Ceremonial  prob_Private Matters/Cerenomial  \\\n",
       "0                         0.056214                         0.002836   \n",
       "1                         0.021440                         0.004048   \n",
       "2                         0.037610                         0.003028   \n",
       "3                         0.021698                         0.001397   \n",
       "4                         0.016508                         0.002295   \n",
       "\n",
       "   prob_Public Finance  prob_Religious Issues  prob_Trials  \n",
       "0             0.050063               0.224099     0.124481  \n",
       "1             0.580476               0.108299     0.011705  \n",
       "2             0.147314               0.132154     0.013860  \n",
       "3             0.103176               0.071109     0.043408  \n",
       "4             0.530751               0.205464     0.012420  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_with_predictions = tcu.predict_from_embedding_cache(\n",
    "    embedding_cache=embedding_cache,\n",
    "    df=df_test,\n",
    "    id_col='new_speech_id',\n",
    "    model=model,\n",
    "    mlb=mlb,\n",
    "    batch_size=128  # Can use larger batch size since embeddings are pre-computed\n",
    ")\n",
    "\n",
    "df_test_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45055061-4712-48a6-891f-3809400175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4284\n",
      "Number of unique topics: 8\n",
      "Topics: ['Other', 'Politics: Domestic', 'Politics: Foreign', 'Private Matters/Ceremonial', 'Private Matters/Cerenomial', 'Public Finance', 'Religious Issues', 'Trials']\n"
     ]
    }
   ],
   "source": [
    "test_prob_cols = [col for col in df_test_with_predictions.columns if col.startswith('prob_')]\n",
    "y_probs = df_test_with_predictions[test_prob_cols].values\n",
    "\n",
    "# Get true labels in binary format (need to use original df_val_sample with topics)\n",
    "val_texts, y_true, mlb_val, labels = tcu.prepare_multilabel_data(\n",
    "    df=df_test_with_predictions, \n",
    "    text_col='speech', \n",
    "    label_col='topic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a84481f-d662-49c1-861d-3801c4cd5edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Computing Optimal Thresholds (All Strategies) ===\n",
      "\n",
      "1. Minimize FN (Cost-Sensitive Approach)...\n",
      "   Threshold: 0.1667 | F1 Macro: 0.5210 | F1 Micro: 0.7868\n",
      "\n",
      "2. Minimize FP (Precision-Optimized)...\n",
      "   Threshold: 0.4183 | F1 Macro: 0.4789 | F1 Micro: 0.8112\n",
      "\n",
      "3. Per-Class F1 Optimization (Balanced)...\n",
      "   Avg Threshold: 0.2258 | F1 Macro: 0.5747 | F1 Micro: 0.8156\n",
      "\n",
      "==================================================\n",
      "Summary of All Strategies:\n",
      "  Minimize FN (Recall):     0.1667 (F1 Macro: 0.5210)\n",
      "  Minimize FP (Precision):  0.4183 (F1 Macro: 0.4789)\n",
      "  Per-Class F1 (Balanced):  0.2258 avg (F1 Macro: 0.5747)\n",
      "==================================================\n",
      "\n",
      "0.5209828157178662\n",
      "0.47894301485868096\n",
      "0.5747347454931437\n"
     ]
    }
   ],
   "source": [
    "# Find optimal threshold\n",
    "# Strategy options:\n",
    "# - 'minimize_fn': Minimize false negatives (optimize recall) - good for not missing topics\n",
    "# - 'minimize_fp': Minimize false positives (optimize precision) - good for avoiding wrong topics\n",
    "# - 'per_class': Find optimal threshold for each class separately\n",
    "# Get all thresholds at once\n",
    "reload(tcu)\n",
    "results = tcu.find_optimal_thresholds_multilabel(y_true, y_probs, mlb)\n",
    "\n",
    "# Access specific strategies\n",
    "fn_threshold = results['minimize_fn']['global_threshold']\n",
    "fp_threshold = results['minimize_fp']['global_threshold']\n",
    "pc_thresholds = results['per_class_f1']['per_class_thresholds']\n",
    "\n",
    "# Compare F1 scores\n",
    "print(results['minimize_fn']['f1_macro'])\n",
    "print(results['minimize_fp']['f1_macro'])\n",
    "print(results['per_class_f1']['f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30f93e23-216d-401e-a315-e89b7b89e000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_speech_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>speech</th>\n",
       "      <th>ID</th>\n",
       "      <th>prob_Other</th>\n",
       "      <th>prob_Politics: Domestic</th>\n",
       "      <th>prob_Politics: Foreign</th>\n",
       "      <th>prob_Private Matters/Ceremonial</th>\n",
       "      <th>prob_Private Matters/Cerenomial</th>\n",
       "      <th>prob_Public Finance</th>\n",
       "      <th>prob_Religious Issues</th>\n",
       "      <th>prob_Trials</th>\n",
       "      <th>parsed_topics</th>\n",
       "      <th>predicted_topic_fn_threshold</th>\n",
       "      <th>predicted_topic_fp_threshold</th>\n",
       "      <th>predicted_topic_pc_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>My Lords and gentlemen; I hope that you do rem...</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.933067</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.050063</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>0.124481</td>\n",
       "      <td>[Politics: Domestic]</td>\n",
       "      <td>Politics: Domestic, Religious Issues</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>Politics: Domestic, Religious Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>the king's main reason of calling the parliame...</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>0.015721</td>\n",
       "      <td>0.761333</td>\n",
       "      <td>0.404397</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.580476</td>\n",
       "      <td>0.108299</td>\n",
       "      <td>0.011705</td>\n",
       "      <td>[Politics: Domestic]</td>\n",
       "      <td>Politics: Domestic, Politics: Foreign, Public ...</td>\n",
       "      <td>Politics: Domestic, Public Finance</td>\n",
       "      <td>Politics: Domestic, Politics: Foreign, Public ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politics: Domestic, Religious Issues, Public F...</td>\n",
       "      <td>\"That his majesty had amply accepted the Speak...</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.960059</td>\n",
       "      <td>0.128712</td>\n",
       "      <td>0.037610</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.147314</td>\n",
       "      <td>0.132154</td>\n",
       "      <td>0.013860</td>\n",
       "      <td>[Politics: Domestic, Religious Issues, Public ...</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>\"That the late dictates between the late King ...</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.984181</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>0.021698</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.103176</td>\n",
       "      <td>0.071109</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>[Politics: Domestic]</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Politics: Domestic</td>\n",
       "      <td>there might be no Committees for Grievances or...</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.960703</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.530751</td>\n",
       "      <td>0.205464</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>[Politics: Domestic]</td>\n",
       "      <td>Politics: Domestic, Public Finance, Religious ...</td>\n",
       "      <td>Politics: Domestic, Public Finance</td>\n",
       "      <td>Politics: Domestic, Public Finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_speech_id                                              topic  \\\n",
       "0              1                                 Politics: Domestic   \n",
       "1              2                                 Politics: Domestic   \n",
       "2              3  Politics: Domestic, Religious Issues, Public F...   \n",
       "3              4                                 Politics: Domestic   \n",
       "4              5                                 Politics: Domestic   \n",
       "\n",
       "                                              speech       ID  prob_Other  \\\n",
       "0  My Lords and gentlemen; I hope that you do rem...  10001.0    0.011698   \n",
       "1  the king's main reason of calling the parliame...  10013.0    0.015721   \n",
       "2  \"That his majesty had amply accepted the Speak...  10013.0    0.023805   \n",
       "3  \"That the late dictates between the late King ...   1321.0    0.009132   \n",
       "4  there might be no Committees for Grievances or...    316.0    0.013387   \n",
       "\n",
       "   prob_Politics: Domestic  prob_Politics: Foreign  \\\n",
       "0                 0.933067                0.022387   \n",
       "1                 0.761333                0.404397   \n",
       "2                 0.960059                0.128712   \n",
       "3                 0.984181                0.024302   \n",
       "4                 0.960703                0.039627   \n",
       "\n",
       "   prob_Private Matters/Ceremonial  prob_Private Matters/Cerenomial  \\\n",
       "0                         0.056214                         0.002836   \n",
       "1                         0.021440                         0.004048   \n",
       "2                         0.037610                         0.003028   \n",
       "3                         0.021698                         0.001397   \n",
       "4                         0.016508                         0.002295   \n",
       "\n",
       "   prob_Public Finance  prob_Religious Issues  prob_Trials  \\\n",
       "0             0.050063               0.224099     0.124481   \n",
       "1             0.580476               0.108299     0.011705   \n",
       "2             0.147314               0.132154     0.013860   \n",
       "3             0.103176               0.071109     0.043408   \n",
       "4             0.530751               0.205464     0.012420   \n",
       "\n",
       "                                       parsed_topics  \\\n",
       "0                               [Politics: Domestic]   \n",
       "1                               [Politics: Domestic]   \n",
       "2  [Politics: Domestic, Religious Issues, Public ...   \n",
       "3                               [Politics: Domestic]   \n",
       "4                               [Politics: Domestic]   \n",
       "\n",
       "                        predicted_topic_fn_threshold  \\\n",
       "0               Politics: Domestic, Religious Issues   \n",
       "1  Politics: Domestic, Politics: Foreign, Public ...   \n",
       "2                                 Politics: Domestic   \n",
       "3                                 Politics: Domestic   \n",
       "4  Politics: Domestic, Public Finance, Religious ...   \n",
       "\n",
       "         predicted_topic_fp_threshold  \\\n",
       "0                  Politics: Domestic   \n",
       "1  Politics: Domestic, Public Finance   \n",
       "2                  Politics: Domestic   \n",
       "3                  Politics: Domestic   \n",
       "4  Politics: Domestic, Public Finance   \n",
       "\n",
       "                        predicted_topic_pc_threshold  \n",
       "0               Politics: Domestic, Religious Issues  \n",
       "1  Politics: Domestic, Politics: Foreign, Public ...  \n",
       "2                                 Politics: Domestic  \n",
       "3                                 Politics: Domestic  \n",
       "4                 Politics: Domestic, Public Finance  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reload(tcu)\n",
    "df_test_with_predictions = tcu.make_predictions(df_test_with_predictions, fn_threshold) \n",
    "df_test_with_predictions = tcu.make_predictions(df_test_with_predictions, fp_threshold) \n",
    "df_test_with_predictions = tcu.make_predictions(df_test_with_predictions, pc_thresholds) \n",
    "df_test_with_predictions.rename(columns={f'predicted_topic_{fn_threshold}': 'predicted_topic_fn_threshold'}, inplace=True)\n",
    "df_test_with_predictions.rename(columns={f'predicted_topic_{fp_threshold}': 'predicted_topic_fp_threshold'}, inplace=True)\n",
    "df_test_with_predictions.rename(columns={f'predicted_topic_per_class': 'predicted_topic_pc_threshold'}, inplace=True)\n",
    "\n",
    "df_test_with_predictions.head()\n",
    "\n",
    "df_test_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "948a1d25-fdcb-4d1f-b4f9-9cfb5d8b1eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Predictions ===\n",
      "Total samples: 4284\n",
      "Number of classes: 8\n",
      "\n",
      "==================================================\n",
      "F1 Scores:\n",
      "  Macro F1: 0.5210\n",
      "  Micro F1: 0.7868\n",
      "==================================================\n",
      "\n",
      "Confusion Matrix per Class:\n",
      "==================================================\n",
      "\n",
      "Class: Other\n",
      "  TP (True Positives):     2  |  FP (False Positives):    8\n",
      "  FN (False Negatives):   46  |  TN (True Negatives):  4228\n",
      "  Precision: 0.200  |  Recall: 0.042  |  F1: 0.069\n",
      "\n",
      "Class: Politics: Domestic\n",
      "  TP (True Positives):  3003  |  FP (False Positives):  774\n",
      "  FN (False Negatives):   19  |  TN (True Negatives):   488\n",
      "  Precision: 0.795  |  Recall: 0.994  |  F1: 0.883\n",
      "\n",
      "Class: Politics: Foreign\n",
      "  TP (True Positives):   480  |  FP (False Positives):  401\n",
      "  FN (False Negatives):  166  |  TN (True Negatives):  3237\n",
      "  Precision: 0.545  |  Recall: 0.743  |  F1: 0.629\n",
      "\n",
      "Class: Private Matters/Ceremonial\n",
      "  TP (True Positives):    45  |  FP (False Positives):   33\n",
      "  FN (False Negatives):  127  |  TN (True Negatives):  4079\n",
      "  Precision: 0.577  |  Recall: 0.262  |  F1: 0.360\n",
      "\n",
      "Class: Private Matters/Cerenomial\n",
      "  TP (True Positives):     0  |  FP (False Positives):    1\n",
      "  FN (False Negatives):    5  |  TN (True Negatives):  4278\n",
      "  Precision: 0.000  |  Recall: 0.000  |  F1: 0.000\n",
      "\n",
      "Class: Public Finance\n",
      "  TP (True Positives):   867  |  FP (False Positives):  440\n",
      "  FN (False Negatives):  214  |  TN (True Negatives):  2763\n",
      "  Precision: 0.663  |  Recall: 0.802  |  F1: 0.726\n",
      "\n",
      "Class: Religious Issues\n",
      "  TP (True Positives):   574  |  FP (False Positives):  299\n",
      "  FN (False Negatives):  164  |  TN (True Negatives):  3247\n",
      "  Precision: 0.658  |  Recall: 0.778  |  F1: 0.713\n",
      "\n",
      "Class: Trials\n",
      "  TP (True Positives):   703  |  FP (False Positives):  296\n",
      "  FN (False Negatives):   82  |  TN (True Negatives):  3203\n",
      "  Precision: 0.704  |  Recall: 0.896  |  F1: 0.788\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "results_fn = tcu.evaluate_trained_model(df_test_with_predictions, 'topic', \"predicted_topic_fn_threshold\", labels, mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a96702c8-072f-4593-a039-3f2572a63de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Predictions ===\n",
      "Total samples: 4284\n",
      "Number of classes: 8\n",
      "\n",
      "==================================================\n",
      "F1 Scores:\n",
      "  Macro F1: 0.4789\n",
      "  Micro F1: 0.8112\n",
      "==================================================\n",
      "\n",
      "Confusion Matrix per Class:\n",
      "==================================================\n",
      "\n",
      "Class: Other\n",
      "  TP (True Positives):     0  |  FP (False Positives):    0\n",
      "  FN (False Negatives):   48  |  TN (True Negatives):  4236\n",
      "  Precision: 0.000  |  Recall: 0.000  |  F1: 0.000\n",
      "\n",
      "Class: Politics: Domestic\n",
      "  TP (True Positives):  2919  |  FP (False Positives):  420\n",
      "  FN (False Negatives):  103  |  TN (True Negatives):   842\n",
      "  Precision: 0.874  |  Recall: 0.966  |  F1: 0.918\n",
      "\n",
      "Class: Politics: Foreign\n",
      "  TP (True Positives):   319  |  FP (False Positives):   88\n",
      "  FN (False Negatives):  327  |  TN (True Negatives):  3550\n",
      "  Precision: 0.784  |  Recall: 0.494  |  F1: 0.606\n",
      "\n",
      "Class: Private Matters/Ceremonial\n",
      "  TP (True Positives):     5  |  FP (False Positives):    1\n",
      "  FN (False Negatives):  167  |  TN (True Negatives):  4111\n",
      "  Precision: 0.833  |  Recall: 0.029  |  F1: 0.056\n",
      "\n",
      "Class: Private Matters/Cerenomial\n",
      "  TP (True Positives):     0  |  FP (False Positives):    0\n",
      "  FN (False Negatives):    5  |  TN (True Negatives):  4279\n",
      "  Precision: 0.000  |  Recall: 0.000  |  F1: 0.000\n",
      "\n",
      "Class: Public Finance\n",
      "  TP (True Positives):   683  |  FP (False Positives):  124\n",
      "  FN (False Negatives):  398  |  TN (True Negatives):  3079\n",
      "  Precision: 0.846  |  Recall: 0.632  |  F1: 0.724\n",
      "\n",
      "Class: Religious Issues\n",
      "  TP (True Positives):   452  |  FP (False Positives):   78\n",
      "  FN (False Negatives):  286  |  TN (True Negatives):  3468\n",
      "  Precision: 0.853  |  Recall: 0.612  |  F1: 0.713\n",
      "\n",
      "Class: Trials\n",
      "  TP (True Positives):   631  |  FP (False Positives):  132\n",
      "  FN (False Negatives):  154  |  TN (True Negatives):  3367\n",
      "  Precision: 0.827  |  Recall: 0.804  |  F1: 0.815\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "results_fn = tcu.evaluate_trained_model(df_test_with_predictions, 'topic', \"predicted_topic_fp_threshold\", labels, mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d11104bf-09e3-4f9e-850c-7ad8a25c0bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating Predictions ===\n",
      "Total samples: 4284\n",
      "Number of classes: 8\n",
      "\n",
      "==================================================\n",
      "F1 Scores:\n",
      "  Macro F1: 0.5747\n",
      "  Micro F1: 0.8156\n",
      "==================================================\n",
      "\n",
      "Confusion Matrix per Class:\n",
      "==================================================\n",
      "\n",
      "Class: Other\n",
      "  TP (True Positives):     5  |  FP (False Positives):   23\n",
      "  FN (False Negatives):   43  |  TN (True Negatives):  4213\n",
      "  Precision: 0.179  |  Recall: 0.104  |  F1: 0.132\n",
      "\n",
      "Class: Politics: Domestic\n",
      "  TP (True Positives):  2899  |  FP (False Positives):  392\n",
      "  FN (False Negatives):  123  |  TN (True Negatives):   870\n",
      "  Precision: 0.881  |  Recall: 0.959  |  F1: 0.918\n",
      "\n",
      "Class: Politics: Foreign\n",
      "  TP (True Positives):   421  |  FP (False Positives):  210\n",
      "  FN (False Negatives):  225  |  TN (True Negatives):  3428\n",
      "  Precision: 0.667  |  Recall: 0.652  |  F1: 0.659\n",
      "\n",
      "Class: Private Matters/Ceremonial\n",
      "  TP (True Positives):    69  |  FP (False Positives):   94\n",
      "  FN (False Negatives):  103  |  TN (True Negatives):  4018\n",
      "  Precision: 0.423  |  Recall: 0.401  |  F1: 0.412\n",
      "\n",
      "Class: Private Matters/Cerenomial\n",
      "  TP (True Positives):     3  |  FP (False Positives):   28\n",
      "  FN (False Negatives):    2  |  TN (True Negatives):  4251\n",
      "  Precision: 0.097  |  Recall: 0.600  |  F1: 0.167\n",
      "\n",
      "Class: Public Finance\n",
      "  TP (True Positives):   781  |  FP (False Positives):  210\n",
      "  FN (False Negatives):  300  |  TN (True Negatives):  2993\n",
      "  Precision: 0.788  |  Recall: 0.722  |  F1: 0.754\n",
      "\n",
      "Class: Religious Issues\n",
      "  TP (True Positives):   548  |  FP (False Positives):  204\n",
      "  FN (False Negatives):  190  |  TN (True Negatives):  3342\n",
      "  Precision: 0.729  |  Recall: 0.743  |  F1: 0.736\n",
      "\n",
      "Class: Trials\n",
      "  TP (True Positives):   649  |  FP (False Positives):  148\n",
      "  FN (False Negatives):  136  |  TN (True Negatives):  3351\n",
      "  Precision: 0.814  |  Recall: 0.827  |  F1: 0.820\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "results_fn = tcu.evaluate_trained_model(df_test_with_predictions, 'topic', \"predicted_topic_pc_threshold\", labels, mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e47b06a-317d-42ad-99c5-863853cb6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions (topics and probabilities) to 'candidates_with_predictions.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Change according to your own preferences!\n",
    "best_threshold = fn_threshold\n",
    "\n",
    "df_candidates_with_predictions = tcu.make_predictions(df_candidates_with_predictions, best_threshold)\n",
    "\n",
    "df_candidates_with_predictions.to_excel('candidates_with_predictions.xlsx', index=False)\n",
    "print(\"Saved predictions (topics and probabilities) to 'candidates_with_predictions.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66bd317-9f30-4a3f-92d2-2d6e72277d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
